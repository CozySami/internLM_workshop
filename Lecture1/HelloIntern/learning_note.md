## 书生·浦语2.5概览

### 推理能力领先
- 支持 100 万字上下文
- 自主规则和搜索, 完成复杂任务
- 综合推理能力提升 20%, 基于 InterLM2 性能

### 核心技术思路： 高质量合成数据
  - 基于规则的数据构造
  - 基于模型的数据扩充
  - 基于反馈的数据生成

### 书生·浦语开源模型系统
    - 1.8B - 超轻量级, 可用于端侧应用或者开发者快速学习上手
    - 7B - 模型轻便但能不低, 为轻量级的研究和应用提供强力支撑
    - 20B - 模型的综合性能更为强劲, 可以有效支持更加复杂的实用场景
    - 102B - 性能强大的闭源模型, 兼顾业界表现达到 GPI-4
    - InternLM-XComposer (灵箭)
    - InternLM-Math (数学)
    - InternLM-WQX (文曲星)

## 全链条开源
    - MindSearch - 思索式开源搜索应用
    - Lagent - 首个支持代码解释的智能代码框架
    - MinerU - 高效文档解析工具
    - HuixiangDou - 基于专业知识库的群聊助手
    - OpenCompass - 社区最全面的开源评测体系
    - LMDeploy - 性能超过国际主流推理框架 Vim
    - InternLM - 系列模型

### 开源数据处理工具箱
- Miner U - 一站式开源高质量数据提取工具, 支持多格式 (PDF/网页/电子书), 智能采取, 生成高质量预训练数据
- Label LLM - 专业数字化 LLM 对话标注, 通过灵活多变的工具配置与多种数据模态的"兼容性", 为大规模身材制造高质量的标注数据
- Label U - 一站式轻量级开源标注工具, 自由组合多样工具, 无缝兼容各格式数据, 同时支持视觉、音频多种数据标注, 加速数据标注效率

#### 微调 XTuner
    - 高效微调框架 XTuner
    - 适配多种生态
    - 多种微调算法, 覆盖各类应用场景
    - 适配多种开源生态
    - 支持加载 HuggingFace、ModelScope 模型或数据集
    - 自动优化加速
    - 开发者无需关注复杂的显存优化与计算加速细节
    - 支持千亿参数+ 百万上下文训练
    - 适配多种硬件
    - 训练方案覆盖 NVIDIA 20 系列以上所有显卡
    - 最低只需 8GB 显存即可微调 7B 模型

### 轻量级智能体框架 Lagent  
- 支持多种类型的智能体能力
  - ReAct - 输入、选择工具、执行工具
  - ReWoo - 输入、计划执行、DAG
  - AutoGPT - 接收工具、执行工具、人工干预
- 支持多种大语言模型
  - GPT-3.5/4
  - Hugging Face Transformers
  - InternLM
  - Llama
- 集成易拓展的 AI 工具
  - 文生图、搜索、出行 API、财经 API
  - 文本生成、计算器、代码解释器
  - 图片描述、体育资讯 API

### HuixiangDou 是群聊场景 LLM 知识助手  
    - 检索增强生成(RAG), 非参数记忆, 利用外部知识库提供实时更新的信息
    - 结构化知识库匹配意图, 行为可解释
    - 无关问题不吭声, 明确回答的直接回复
    - 不违背核心价值观